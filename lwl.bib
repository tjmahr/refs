@incollection {FernaldLWL,
  author    = {Fernald, Anne and Zangl, Renate and Portillo, Ana Luz and Marchman, Virginia A},
  title     = {Looking while listening: Using eye movements to monitor spoken language comprehension by infants and young children},
  editor    = {Sekerina, Irina A and Fern{\'a}ndez, Eva M and Clahsen, Harald},
  booktitle = {Developmental Psycholinguistics: On-line methods in children's language processing},
  publisher = {John Benjamins Publishing Company},
  address   = {Amsterdam},
  year      = {2008},
  pages     = {97--135},
  abstract  = {The "looking-while-listening" methodology uses real-time 
               measures of the time course of young children's gaze patterns in 
               response to speech. This procedure is low in task demands and does not 
               require automated eyetracking technology, similar to 
               "preferential-looking" procedures. However, the looking-while-listening 
               methodology differs critically from preferential-looking procedures in 
               the methods used for data reduction and analysis, yielding 
               high-resolution measures of speech processing from moment to moment, 
               rather than relying on summary measures of looking preference. Because 
               children's gaze patterns are time-locked to the speech signal and coded 
               frame-by-frame, response latencies can be coded with millisecond 
               precision on multiple trials over multiple items, based on data from 
               thousands of frames in each experiment. The meticulous procedures 
               required in the collection, reduction, and multiple levels of analysis 
               of such detailed data are demanding, but well worth the effort, 
               revealing a dynamic and nuanced picture of young children's developing 
               skill in finding meaning in spoken language.}, 
}

@article {GowMcMurray2007,
  author  =  {Gow, Jr., David W. and McMurray, Bob},
  title   =  {Word recognition and phonology: The case of {E}nglish coronal place assimilation},
  journal =  {Papers in laboratory phonology},
  volume  =  {9},
  pages   =  {173--200},
  year    =  {2007}
}

@article {Salverda2014,
  author    = {Salverda, Anne Pier and Kleinschmidt, Dave and Tanenhaus, Michael K.},
  title     = {Immediate effects of anticipatory coarticulation in spoken-word recognition},
  doi       = {10.1016/j.jml.2013.11.002},
  journal   = {Journal of memory and language},
  number    = {1},
  pages     = {145--163},
  publisher = {Elsevier},
  url       = {http://www.ncbi.nlm.nih.gov/pubmed/24511179},
  volume    = {71},
  year      = {2014},
  abstract  = {Two visual-world experiments examined listeners' use of pre 
               word-onset anticipatory coarticulation in spoken-word recognition. 
               Experiment 1 established the shortest lag with which information in the 
               speech signal influences eye-movement control, using stimuli such as 
               "The \ldots ladder is the target". With a neutral token of the definite 
               article preceding the target word, saccades to the referent were not 
               more likely than saccades to an unrelated distractor until 200-240 ms 
               after the onset of the target word. In Experiment 2, utterances 
               contained definite articles which contained natural anticipatory 
               coarticulation pertaining to the onset of the target word ("The ladder 
               \ldots is the target"). A simple Gaussian classifier was able to predict 
               the initial sound of the upcoming target word from formant information 
               from the first few pitch periods of the article's vowel. With these 
               stimuli, effects of speech on eye-movement control began about 70 ms 
               earlier than in Experiment 1, suggesting rapid use of anticipatory 
               coarticulation. The results are interpreted as support for "data 
               explanation" approaches to spoken-word recognition. Methodological 
               implications for visual-world studies are also discussed.}, 
}

@article {Weisleder2013,
  author   = {Weisleder, Adriana and Fernald, Anne},
  title    = {Talking to children matters: early language experience strengthens processing and builds vocabulary},
  doi      = {10.1177/0956797613488145},
  journal  = {Psychological science},
  number   = {11},
  pages    = {2143--52},
  volume   = {24},
  year     = {2013},
  abstract = {Infants differ substantially in their rates of language 
              growth, and slow growth predicts later academic difficulties. In this 
              study, we explored how the amount of speech directed to infants in 
              Spanish-speaking families low in socioeconomic status influenced the 
              development of children's skill in real-time language processing and 
              vocabulary learning. All-day recordings of parent-infant interactions at 
              home revealed striking variability among families in how much speech 
              caregivers addressed to their child. Infants who experienced more 
              child-directed speech became more efficient in processing familiar words 
              in real time and had larger expressive vocabularies by the age of 24 
              months, although speech simply overheard by the child was unrelated to 
              vocabulary outcomes. Mediation analyses showed that the effect of 
              child-directed speech on expressive vocabulary was explained by infants' 
              language-processing efficiency, which suggests that richer language 
              experience strengthens processing skills that facilitate language 
              growth.}, 
}

@article {MarchmanFernald2008,
  author   = {Marchman, Virginia A and Fernald, Anne},
  title    = {Speed of word recognition and vocabulary knowledge in infancy predict cognitive and language outcomes in later childhood},
  doi      = {10.1111/j.1467-7687.2008.00671.x},
  journal  = {Developmental science},
  number   = {3},
  pages    = {F9--16},
  volume   = {11},
  year     = {2008},
  abstract = {The nature of predictive relations between early language 
              and later cognitive function is a fundamental question in research on 
              human cognition. In a longitudinal study assessing speed of language 
              processing in infancy, Fernald, Perfors and Marchman (2006) found that 
              reaction time at 25 months was strongly related to lexical and 
              grammatical development over the second year. In this follow-up study, 
              children originally tested as infants were assessed at 8 years on 
              standardized tests of language, cognition, and working memory. Speed of 
              spoken word recognition and vocabulary size at 25 months each accounted 
              for unique variance in linguistic and cognitive skills at 8 years, 
              effects that were attributable to strong relations between both infancy 
              measures and working memory. These findings suggest that processing 
              speed and early language skills are fundamental to intellectual 
              functioning, and that language development is guided by learning and 
              representational principles shared across cognitive and linguistic 
              domains.}, 
}

@incollection {LawfulVariability,
  author    = {Elman, Jeffrey L. and McClelland, James L.},
  title     = {Exploiting lawful variability in the speech wave},
  address   = {Hillsdale, NJ},
  booktitle = {Invariance and variability of speech processes},
  editor    = {Perkell, J. S. and Klatt, D. H.},
  pages     = {360--385},
  publisher = {Lawrence Erlbaum Associates, Inc.},
  year      = {1986},
}

@article {SubcatMismatch,
  author  = {Dahan, Delphine and Magnuson, James S. and Tanenhaus, Michael K. and Hogan, Ellen M.},
  title   = {Subcategorical mismatches and the time course of lexical access: Evidence for lexical competition},
  doi     = {10.1080/01690960143000074},
  journal = {Language and Cognitive Processes},
  number  = {5--6},
  pages   = {507--534},
  volume  = {16},
  year    = {2001},
}

@article {McQueen1999,
  title    = {Lexical influence in phonetic decision making: Evidence from subcategorical mismatches},
  author   = {McQueen, James M. and Norris, Dennis and Cutler, Anne},
  doi      = {10.1037/0096-1523.25.5.1363},
  journal  = {Journal of Experimental Psychology: Human Perception and Performance},
  number   = {5},
  pages    = {1363--1389},
  volume   = {25},
  year     = {1999},
  abstract = {In 5 experiments, listeners heard words and nonwords, some 
              cross-spliced so that they contained acoustic-phonetic mismatches. 
              Performance was worse on mismatching than on matching items. Words 
              cross-spliced with words and words cross-spliced with nonwords produced 
              parallel results. However, in lexical decision and 1 of 3 phonetic 
              decision experiments, performance on nonwords cross-spliced with words 
              was poorer than on nonwords cross-spliced with nonwords. A gating study 
              confirmed that there were misleading coarticulatory cues in the 
              cross-spliced items; a sixth experiment showed that the earlier results 
              were not due to interitem differences in the strength of these cues. 
              Three models of phonetic decision making (the Race model, the TRACE 
              model, and a postlexical model) did not explain the data. A new 
              bottom-up model is outlined that accounts for the findings in terms of 
              lexical involvement at a dedicated decision-making stage.}, 
}

@inproceedings {Tobin2010,
  title     = {Effects of anticipatory coarticulation on lexical access},
  author    = {Tobin, Stephen and Cho, Pyeong Whan and Jennet, Patrick and Magnuson, James S.},
  booktitle = {Proceedings of the 32nd Annual Meeting of the Cognitive Science Society},
  editor    = {Ohlsson, Stellan and Catrambone, Richard},
  pages     = {2200--2205},
  address   = {Austin, TX},
  publisher = {Cognitive Science Society},
  year      = {2010},
  abstract  = {One of the most challenging unsolved problems in cognitive 
               science is lack of invariance in spoken language. We take the view that 
               variability due to coarticulation is systematic and beneficial. Several 
               recent eye tracking experiments have demonstrated listeners' sensitivity 
               to local coarticulatory cues between adjacent phonemes. We examined 
               sensitivity to longer-range, anticipatory vowel-to-vowel coarticulation, 
               which can spread across multiple syllables. Using a variant of the 
               Visual World eye tracking paradigm (Tanenhaus et al., 1995), we 
               conducted the first on-line test of whether lexical access is sensitive 
               to such subtle, long-range cues, and whether the impact of such cues is 
               modulated by the coarticulation resistance of intervening segments. 
               Lexical access was delayed when misleading anticipatory coarticulation 
               was available in cross-spliced materials. This significantly extends the 
               nature and temporal range of subcategorical cues known to influence 
               on-line sentence comprehension, and demonstrates that lexical access is 
               simultaneously constrained by information at multiple temporal grains.}, 
}

@incollection {Fisher2004,
  title     = {Learning to identify spoken words},
  author    = {Fisher, Cynthia and Church, Barbara A. and Chambers, Kyle E},
  booktitle = {Weaving a lexicon},
  editor    = {Hall, D. Geoffrey and Waxman, Sandra R.},
  pages     = {3--40},
  address   = {Cambridge, MA},
  publisher = {MIT Press},
  year      = {2004},
}

@article {JohnsonJusczyk2001,
  title    = {Word Segmentation by 8-Month-Olds: When Speech Cues Count More Than Statistics},
  author   = {Johnson, Elizabeth K. and Jusczyk, Peter W.},
  doi      = {10.1006/jmla.2000.2755},
  journal  = {Journal of Memory and Language},
  number   = {4},
  pages    = {548--567},
  volume   = {44},
  year     = {2001},
  abstract = {Fluent speech contains few pauses between adjacent words. 
              Cues such as stress, phonotactic constraints, and the statistical 
              structure of the input aid infants in discovering word boundaries. None 
              of the many available segmentation cues is foolproof. So, we used the 
              headturn preference procedure to investigate infants' integration of 
              multiple cues. We also explored whether infants find speech cues 
              produced by coarticulation useful in word segmentation. Using natural 
              speech syllables, we replicated Saffran, Aslin, et al.'s (1996) study 
              demonstrating that 8-month-olds can segment a continuous stream of 
              speech based on statistical cues alone. Next, we added conflicting 
              segmentation cues. Experiment 2 pitted stress against statistics, 
              whereas Experiment 3 pitted coarticulation against statistics. In both 
              cases, 8-month-olds weighed speech cues more heavily than statistical 
              cues. This observation was verified in Experiment 4, which indicated 
              that greater complexity of the familiarization sequence does not 
              necessarily lead to familiarity effects.}, 
}

@article {Swingley1999,
  title    = {Continuous processing in word recognition at 24 months},
  author   = {Swingley, Daniel and Pinto, John P and Fernald, Anne},
  doi      = {10.1016/S0010-0277(99)00021-9},
  journal  = {Cognition},
  number   = {2},
  pages    = {73--108},
  volume   = {71},
  year     = {1999},
  abstract = {Speech processing in adults in continuous: as 
              acoustic-phonetic information is heard, listeners' interpretation of the 
              speech is updated incrementally. The present studies used a visual 
              fixation technique to examine whether young children also interpret 
              speech continuously. In Experiments 1 and 2, 24-month-old children 
              looked at visual displays while hearing sentences. Sentences each 
              contained a target word labeling one of the two displayed pictures. 
              Children's latency to fixate the labeled picture was measured. 
              Children's responses were delayed when the competing distractor 
              picture's label overlapped phonetically with the target at onset 
              (dog-doll), but not when the pictures' labels rhymed (ball-doll), 
              showing that children monitored the speech stream incrementally for 
              acoustic-phonetic information specifying the correct picture. In 
              Experiment 3, adults' responses in the same task were found to be very 
              similar to those of the 24-month-olds. This research shows that by 24 
              months, children can interpret speech continuously.}, 
}

@article {Fernald2001,
  title    = {When half a word is enough: infants can recognize spoken words using partial phonetic information},
  author   = {Fernald, Anne and Swingley, Daniel and Pinto, John P.},
  doi      = {10.1111/1467-8624.00331},
  journal  = {Child development},
  number   = {4},
  pages    = {1003--15},
  volume   = {72},
  year     = {2001},
  abstract = {Adults process speech incrementally, rapidly identifying 
              spoken words on the basis of initial phonetic information sufficient to 
              distinguish them from alternatives. In this study, infants in the second 
              year also made use of word-initial information to understand fluent 
              speech. The time course of comprehension was examined by tracking 
              infants' eye movements as they looked at pictures in response to 
              familiar spoken words, presented both as whole words in intact form and 
              as partial words in which only the first 300 ms of the word was heard. 
              In Experiment 1, 21-month-old infants (N = 32) recognized partial words 
              as quickly and reliably as they recognized whole words; in Experiment 2, 
              these findings were replicated with 18-month-old infants (N = 32). 
              Combining the data from both experiments, efficiency in spoken word 
              recognition was examined in relation to level of lexical development. 
              Infants with more than 100 words in their productive vocabulary were 
              more accurate in identifying familiar words than were infants with less 
              than 60 words. Grouped by response speed, infants with faster mean 
              reaction times were more accurate in word recognition and also had 
              larger productive vocabularies than infants with slower response 
              latencies. These results show that infants in the second year are 
              capable of incremental speech processing even before entering the 
              vocabulary spurt, and that lexical growth is associated with increased 
              speed and efficiency in understanding spoken language.}, 
}

@article {Barr2008,
  title    = {Analyzing ‘visual world’ eyetracking data using multilevel logistic regression},
  author   = {Barr, Dale J.},
  doi      = {10.1016/j.jml.2007.09.002},
  journal  = {Journal of Memory and Language},
  number   = {4},
  pages    = {457--474},
  volume   = {59},
  year     = {2008},
  abstract = {A new framework is offered that uses multilevel logistic 
              regression (MLR) to analyze data from ‘visual world’ eyetracking 
              experiments used in psycholinguistic research. The MLR framework 
              overcomes some of the problems with conventional analyses, making it 
              possible to incorporate time as a continuous variable and gaze location 
              as a categorical dependent variable. The multilevel approach minimizes 
              the need for data aggregation and thus provides a more statistically 
              powerful approach. With MLR, the researcher builds a mathematical model 
              of the overall response curve that separates the response into different 
              temporal components. The researcher can test hypotheses by examining the 
              impact of independent variables and their interactions on these 
              components. A worked example using MLR is provided.}, 
}

@book {Mirman2014,
  title     = {Growth Curve Analysis and Visualization Using {R}},
  author    = {Mirman, Daniel},
  address   = {Boca Raton, FL},
  publisher = {Chapman \& Hall/CRC},
  year      = {2014},
}

@manual {lme4,
  title  = {{lme4}: Linear mixed-effects models using {Eigen} and {S4}},
  author = {Douglas Bates and Martin Maechler and Ben Bolker and Steven Walker},
  year   = {2014},
  note   = {R package version 1.1-7},
  url    = {http://CRAN.R-project.org/package=lme4},
}

@book {MBCDI,
  title     = {{MacArthur-Bates Communicative Development Inventories: User's} Guide and Technical Manual},
  author    = {Larry Fenson and Virginia A. Marchman and Donna J. Thal and Philip S. Dale and J. Steven Reznick and Elizabeth Bates},
  edition   = {2nd ed.},
  year      = {2007},
  publisher = {Brookes},
  address   = {Baltimore, MD},
}

@article {CharlesLuce1990,
  title    = {Similarity neighbourhoods of words in young children's lexicons},
  author   = {Charles-Luce, Jan and Luce, Paul A},
  journal  = {Journal of Child Language},
  volume   = {17},
  number   = {1},
  doi      = {10.1017/S0305000900013180},
  pages    = {205--215},
  year     = {1990},
  abstract = {Similarity neighbourhoods for words in young children's 
              lexicons were investigated using three computerized databases. These 
              databases were representative of three groups of native English 
              speakers: 5-year-olds, 7-year-olds, and adults. Computations relating to 
              the similarity neighbourhoods of words in the children's and adult's 
              lexicon revealed that words in the 5- and 7-year-olds' lexicons have 
              many fewer similar neighbours than the same words analyzed in the adult 
              lexicon. Thus, young children may employ more global recognition 
              strategies because words are more discriminable in memory. The 
              neighbourhood analyses provide a number of insights into the processes 
              of auditory word recognition in children and the possible structural 
              organization of words in the young child's mental lexicon.}, 
}

@article {CharlesLuce1995,
  author   = {Charles-Luce, Jan and Luce, Paul A.},
  title    = {An examination of similarity neighbourhoods in young children's receptive vocabularies},
  journal  = {Journal of Child Language},
  volume   = {22},
  number   = {3},
  year     = {1995},
  pages    = {727--735},
  doi      = {10.1017/S0305000900010023},
  abstract = {Based on an analysis of similarity neighbourhoods of words 
              in children's lexicons, Dollaghan (1994) argues that because of the 
              degree of phonological overlap among lexical items in memory, children 
              must perform detailed acoustic-phonetic analyses in order to recognize 
              spoken words. This is in contradiction to Charles-Luce \& Luce (1990), 
              who reported that the similarity neighbourhoods in younger children's 
              expressive lexicons are sparse relative to older children's and adult 
              lexicons and that young children may be able to use more global word 
              recognition strategies. The current investigation re-examined these 
              issues. Similarity neighbourhoods of young children's RECEPTIVE 
              vocabularies were analysed for three-phoneme, four-phoneme and 
              five-phoneme words. The pattern of the original results from 
              Charles-Luce \& Luce (1990) was replicated.}, 
}

@article {Jusczyk1993WRAPSA,
  title   = {From general to language-specific capacities: The {WRAPSA} model of how speech perception develops},
  author  = {Jusczyk, Peter W.},
  journal = {Journal of Phonetics},
  volume  = {21},
  pages   = {3--28},
  year    = {1993},
}



@article {Edwards2004,
  author   = {Edwards, Jan and Beckman, Mary E. and Munson, Benjamin},
  title    = {The interaction between vocabulary size and phonotactic probability effects on children's production accuracy and fluency in nonword repetition},
  journal  = {Journal of Speech, Language, and Hearing Research},
  year     = {2004},
  doi      = {10.1044/1092-4388(2004/034)},
  number   = {2},
  pages    = {421--36},
  volume   = {47},
  abstract = {Adults' performance on a variety of tasks suggests that 
              phonological processing of nonwords is grounded in generalizations about 
              sublexical patterns over all known words. A small body of research 
              suggests that children's phonological acquisition is similarly based on 
              generalizations over the lexicon. To test this account, production 
              accuracy and fluency were examined in nonword repetitions by 104 
              children and 22 adults. Stimuli were 22 pairs of nonwords, in which one 
              nonword contained a low-frequency or unattested two-phoneme sequence and 
              the other contained a high-frequency sequence. For a subset of these 
              nonword pairs, segment durations were measured. The same sound was 
              produced with a longer duration (less fluently) when it appeared in a 
              low-frequency sequence, as compared to a high-frequency sequence. 
              Low-frequency sequences were also repeated with lower accuracy than 
              high-frequency sequences. Moreover, children with smaller vocabularies 
              showed a larger influence of frequency on accuracy than children with 
              larger vocabularies. Taken together, these results provide support for a 
              model of phonological acquisition in which knowledge of sublexical units 
              emerges from generalizations made over lexical items.}, 
}

@article {Metsala1999,
  author  = {Metsala, Jamie L.},
  title   = {Young children's phonological awareness and nonword repetition as a function of vocabulary development},
  doi     = {10.1037//0022-0663.91.1.3},
  journal = {Journal of Educational Psychology},
  number  = {1},
  pages   = {3--19},
  volume  = {91},
  year    = {1999},
}

@article {PRIMIR,
  author   = {Werker, Janet F. and Curtin, Suzanne},
  title    = {{PRIMIR: A} Developmental Framework of Infant Speech Processing},
  year     = {2005},
  doi      = {10.1080/15475441.2005.9684216},
  journal  = {Language Learning and Development},
  number   = {2},
  pages    = {197--234},
  volume   = {1},
 abstract  = {Over the past few years, there has been an increasing 
              emphasis on studying the link between infant speech perception and later 
              language acquisition. This research has yielded some seemingly 
              contradictory findings: In some studies infants appear to use phonetic 
              and indexical detail that they fail to use in other studies. In this 
              article we present a new, unified framework for accounting for these 
              divergent findings. PRIMIR (a developmental framework for Processing 
              Rich Information from Multidimensional Interactive Representations) 
              assumes there is rich information available in the speech input and that 
              the child picks up and organizes this information along a number of 
              multidimensional interactive planes. Use of this rich information 
              depends on the joint activity of 3 dynamic filters. These filters-the 
              initial biases, the developmental level of the child, and requirements 
              of the specific language task the child is facing-work together to 
              differentially direct attention to 1 (or more) plane. In this article we 
              outline the contradictory data that need to be explained, elucidate 
              PRIMIR, including its underlying assumptions and overall architecture, 
              and compare it to existing frameworks. We conclude by presenting core 
              predictions of PRIMIR.}, 
}

@article {Werker2002,
  author   = {Werker, Janet F. and Fennell, Christopher T. and Corcoran, Kathleen M. and Stager, Christine L.},
  title    = {Infants' Ability to Learn Phonetically Similar Words: Effects of Age and Vocabulary Size},
  year     = {2002},
  doi      = {10.1207/15250000252828226},
  journal  = {Infancy},
  number   = {1},
  pages    = {1--30},
  volume   = {3},
  abstract = {What do novice word learners know about the sound of words? 
              Word-learning tasks suggest that young infants (14 months old) confuse 
              similar-sounding words, whereas mispronunciation detection tasks suggest 
              that slightly older infants (18–24 months old) correctly distinguish 
              similar words. Here we explore whether the difficulty at 14 months stems 
              from infants' novice status as word learners or whether it is inherent 
              in the task demands of learning new words. Results from 3 experiments 
              support a developmental explanation. In Experiment 1, infants of 20 
              months learned to pair 2 phonetically similar words to 2 different 
              objects under precisely the same conditions that infants of 14 months 
              (Experiment 2) failed. In Experiment 3, infants of 17 months showed 
              intermediate, but still successful, performance in the task. Vocabulary 
              size predicted word-learning performance, but only in the younger, less 
              experienced word learners. The implications of these results for 
              theories of word learning and lexical representation are discussed.}, 
}

@article {Dollaghan1994,
  title   = {Children's phonological neighbourhoods: half empty or half full?},
  author  = {Dollaghan, Christine A.},
  journal = {Journal of Child Language},
  volume  = {21},
  number  = {2},
  pages   = {257--271},
  year    = {1994},
  doi     = {10.1017/S0305000900009260},
}

@article {Swingley2002,
  author   = {Swingley, Daniel and Aslin, Richard N.},
  title    = {Lexical Neighborhoods and the Word-Form Representations of 14-Month-Olds},
  doi      = {10.1111/1467-9280.00485},
  year     = {2002},
  journal  = {Psychological Science},
  number   = {5},
  pages    = {480--484},
  volume   = {13},
  abstract = {The degree to which infants represent phonetic detail in 
              words has been a source of controversy in phonology and developmental 
              psychology. One prominent hypothesis holds that infants store words in a 
              vague or inaccurate form until the learning of similar-sounding 
              neighbors forces attention to subtle phonetic distinctions. In the 
              experiment reported here, we used a visual fixation task to assess word 
              recognition. We present the first evidence indicating that, in fact, the 
              lexical representations of 14- and 15-month-olds are encoded in fine 
              detail, even when this detail is not functionally necessary for 
              distinguishing similar words in the infant's vocabulary. Exposure to 
              words is sufficient for well-specified lexical representations, even 
              well before the vocabulary spurt. These results suggest developmental 
              continuity in infants' representations of speech: As infants begin to 
              build a vocabulary and learn word meanings, they use the perceptual 
              abilities previously demonstrated in tasks testing the discrimination 
              and categorization of meaningless syllables.}, 
}

@article {Swingley2000,
  author   = {Swingley, Daniel and Aslin, Richard N.},
  title    = {Spoken word recognition and lexical representation in very young children},
  journal  = {Cognition},
  number   = {2},
  pages    = {147--66},
  url      = {http://www.ncbi.nlm.nih.gov/pubmed/10856741},
  volume   = {76},
  year     = {2000},
  abstract = {Although children's knowledge of the sound patterns of 
              words has been a focus of debate for many years, little is known about 
              the lexical representations very young children use in word recognition. 
              In particular, researchers have questioned the degree of specificity 
              encoded in early lexical representations. The current study addressed 
              this issue by presenting 18-23-month-olds with object labels that were 
              either correctly pronounced, or mispronounced. Mispronunciations 
              involved replacement of one segment with a similar segment, as in 
              'baby-vaby'. Children heard sentences containing these words while 
              viewing two pictures, one of which was the referent of the sentence. 
              Analyses of children's eye movements showed that children recognized the 
              spoken words in both conditions, but that recognition was significantly 
              poorer when words were mispronounced. The effects of mispronunciation on 
              recognition were unrelated to age or to spoken vocabulary size. The 
              results suggest that children's representations of familiar words are 
              phonetically well-specified, and that this specification may not be a 
              consequence of the need to differentiate similar words in production.}, 
}

@article {WhiteMorgan2008,
  author   = {White, Katherine S. and Morgan, James L.},
  title    = {Sub-segmental detail in early lexical representations},
  year     = {2008},
  doi      = {10.1016/j.jml.2008.03.001},
  journal  = {Journal of Memory and Language},
  number   = {1},
  pages    = {114--132},
  volume   = {59},
}

@article {TRACE_Mispro,
  author   = {Mayor, Julien and Plunkett, Kim},
  title    = {Infant word recognition: Insights from {TRACE} simulations},
  year     = {2014},
  doi      = {10.1016/j.jml.2013.09.009},
  journal  = {Journal of Memory and Language},
  number   = {1},
  pages    = {89--123},
  volume   = {71},
  abstract = {The TRACE model of speech perception (McClelland \& Elman, 
              1986) is used to simulate results from the infant word recognition 
              literature, to provide a unified, theoretical framework for interpreting 
              these findings. In a first set of simulations, we demonstrate how TRACE 
              can reconcile apparently conflicting findings suggesting, on the one 
              hand, that consonants play a pre-eminent role in lexical acquisition 
              (Nespor, Pe\~{n}a \& Mehler, 2003; Nazzi, 2005), and on the other, that 
              there is a symmetry in infant sensitivity to vowel and consonant 
              mispronunciations of familiar words (Mani \& Plunkett, 2007). In a 
              second series of simulations, we use TRACE to simulate infants' graded 
              sensitivity to mispronunciations of familiar words as reported by White 
              and Morgan (2008). An unexpected outcome is that TRACE fails to 
              demonstrate graded sensitivity for White and Morgan's stimuli unless the 
              inhibitory parameters in TRACE are substantially reduced. We explore the 
              ramifications of this finding for theories of lexical development. 
              Finally, TRACE mimics the impact of phonological neighbourhoods on early 
              word learning reported by Swingley and Aslin (2007). TRACE offers an 
              alternative explanation of these findings in terms of mispronunciations 
              of lexical items rather than imputing word learning to infants. Together 
              these simulations provide an evaluation of Developmental (Jusczyk, 1993) 
              and Familiarity (Metsala, 1999) accounts of word recognition by infants 
              and young children. The findings point to a role for both theoretical 
              approaches whereby vocabulary structure and content constrain infant 
              word recognition in an experience-dependent fashion, and highlight the 
              continuity in the processes and representations involved in lexical 
              development during the second year of life.}, 
}


@article {Gow2002,
  author  = {Gow, Jr., David W.},
  title   = {Does {E}nglish coronal place assimilation create lexical ambiguity?},
  year    = {2002},
  journal = {Journal of Experimental Psychology: Human Perception and Performance},
  doi     = {10.1037/0096-1523.28.1.163},
  number  = {1},
  pages   = {163--179},
  volume  = {28},
}

@article {Mattys2005,
  author   = {Mattys, Sven L. and White, Laurence and Melhorn, James F.},
  title    = {Integration of multiple speech segmentation cues: a hierarchical framework},
  year     = {2005},
  doi      = {10.1037/0096-3445.134.4.477},
  journal  = {Journal of Experimental Psychology: General},
  number   = {4},
  pages    = {477--500},
  volume   = {134},
  abstract = {A central question in psycholinguistic research is how 
              listeners isolate words from connected speech despite the paucity of 
              clear word-boundary cues in the signal. A large body of empirical 
              evidence indicates that word segmentation is promoted by both lexical 
              (knowledge-derived) and sublexical (signal-derived) cues. However, an 
              account of how these cues operate in combination or in conflict is 
              lacking. The present study fills this gap by assessing speech 
              segmentation when cues are systematically pitted against each other. The 
              results demonstrate that listeners do not assign the same power to all 
              segmentation cues; rather, cues are hierarchically integrated, with 
              descending weights allocated to lexical, segmental, and prosodic cues. 
              Lower level cues drive segmentation when the interpretive conditions are 
              altered by a lack of contextual and lexical information or by white 
              noise. Taken together, the results call for an integrated, hierarchical, 
              and signal-contingent approach to speech segmentation.}, 
}


@incollection {Plunkett2006,
  author    = {Plunkett, Kim},
  title     = {Learning how to be flexible with words},
  year      = {2006},
  address   = {Cambridge, MA},
  booktitle = {Processes of change in brain and cognitive development: Attention and performance},
  editor    = {Munakata, Y. and Johnson, M.},
  pages     = {233--248},
  publisher = {MIT Press},
  volume    = {XXI},
}
